{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup\n",
    "import os\n",
    "\n",
    "# os.chdir(f'/content/OurDDPM')\n",
    "os.makedirs(\"checkpoint\", exist_ok=True)\n",
    "os.makedirs(\"precomputed\", exist_ok=True)\n",
    "os.makedirs(\"pretrained\", exist_ok=True)\n",
    "os.makedirs(\"runs\", exist_ok=True)\n",
    "os.makedirs(\"runs/interpolation\", exist_ok=True)\n",
    "\n",
    "from ourddpm import OurDDPM\n",
    "from main import dict2namespace\n",
    "import argparse\n",
    "import yaml\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pdb\n",
    "import cv2\n",
    "import glob\n",
    "# from google.colab.patches import cv2_imshow\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "\n",
    "model_path = os.path.join(\"pretrained/celeba_hq.ckpt\")\n",
    "\n",
    "exp_dir = f\"runs/guided\"\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "n_step =  999#@param {type: \"integer\"}\n",
    "sampling = \"ddpm\" #@param [\"ddpm\", \"ddim\"]\n",
    "fixed_xt = True #@param {type: \"boolean\"}\n",
    "add_var = True #@param {type: \"boolean\"}\n",
    "add_var_on = \"0-999\" #@param {type: \"string\"}\n",
    "vis_gen =  True #@param {type: \"boolean\"}\n",
    "\n",
    "# torch.cuda.set_device(7)\n",
    "\n",
    "args_dic = {\n",
    "    'config': 'celeba.yml', \n",
    "    'n_step': int(n_step), \n",
    "    'sample_type': sampling, \n",
    "    'eta': 0.0,\n",
    "    'bs_test': 1, \n",
    "    'model_path': model_path, \n",
    "    'hybrid_noise': 0, \n",
    "    'align_face': 0,\n",
    "    'image_folder': exp_dir,\n",
    "    'add_var': bool(add_var),\n",
    "    'add_var_on': add_var_on\n",
    "    }\n",
    "args = dict2namespace(args_dic)\n",
    "\n",
    "with open(os.path.join('configs', args.config), 'r') as f:\n",
    "    config_dic = yaml.safe_load(f)\n",
    "config = dict2namespace(config_dic)\n",
    "\n",
    "\n",
    "if bool(add_var):\n",
    "    var_scheduler = []\n",
    "    periods = add_var_on.split(\",\")\n",
    "    for period in periods:\n",
    "        start = int(period.split(\"-\")[0])\n",
    "        end = int(period.split(\"-\")[1])\n",
    "        for n in range(start,end):\n",
    "            var_scheduler.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    return (img + 1) / 2.0\n",
    "\n",
    "def fuse_and_display(imgs):\n",
    "    imgs = [np.array(e) for e in imgs]\n",
    "    imgs = [normalize(img[0].transpose(1, 2, 0)) for img in imgs]\n",
    "    display = cv2.hconcat(imgs)\n",
    "    # display = cv2.cvtColor(display, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(20, 40))\n",
    "    plt.imshow(display)\n",
    "\n",
    "def display_img(img):\n",
    "    img = normalize(img).permute(1, 2, 0)\n",
    "    plt.figure()\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if \"data_list\" not in locals():\n",
    "#     with open(\"runs/interpolation/data_1.obj\",\"rb\") as f:\n",
    "#         data_list = pickle.load(f)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:7\")\n",
    "config.device = device\n",
    "runner = OurDDPM(args, config, device=device)\n",
    "runner.load_classifier(\"checkpoint/attr_classifier_4_attrs_40.pt\", feature_num=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res_list = []\n",
    "# for i, s in enumerate([1, 2, 3, 4, 5]):\n",
    "for i, s in enumerate([-200, -100, 0, 100, 200]):\n",
    "    print(f\"Processing {i}th sample...\")\n",
    "\n",
    "    xt = data_list[3][\"xt\"]\n",
    "    noise_traj = torch.tensor(data_list[3][\"noise_traj\"]).cuda()\n",
    "    img = runner.guided_generate_ddpm(xt, var_scheduler, runner.classifier, 1, classifier_scale=s, noise_traj=noise_traj)\n",
    "\n",
    "    res_list.append(img.detach().cpu())\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "with open(\"runs/guided/data_smile_1.obj\", \"wb\") as f:\n",
    "    pickle.dump(res_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "with open(\"runs/guided/data_smile_1.obj\", \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "fuse_and_display(results)\n",
    "classifier_score = []\n",
    "for each in results:\n",
    "    t = (torch.ones(1) * 0).cuda()\n",
    "    classifier_score.append(F.sigmoid(runner.classifier(each.cuda(), t)[:]))\n",
    "classifier_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.data_utils import get_dataset, get_dataloader\n",
    "data_root = \"/home/summertony717/data/celeba_hq\"\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = get_dataset(\"CelebA_HQ\", data_root, config)\n",
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train_dataset[i]\n",
    "display_img(img)\n",
    "print(label)\n",
    "i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip  \n",
    "import torch\n",
    "\n",
    "device=torch.device(\"cuda\")\n",
    "\n",
    "a = torch.rand((1, 3, 224, 224)).float().cuda()\n",
    "b = clip_model.encode_text([\"I hate CLIP\"])\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "clip_model.encode_image(a)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1892d8d4b511927aed5306f7fd835e8c1b51a049a06d2628fb7ee2dd284077c9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('python3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1892d8d4b511927aed5306f7fd835e8c1b51a049a06d2628fb7ee2dd284077c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
